{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 1161,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.06459948320413436,
      "grad_norm": 0.43935564160346985,
      "learning_rate": 9.989459889710213e-05,
      "loss": 1.6577,
      "step": 25
    },
    {
      "epoch": 0.12919896640826872,
      "grad_norm": 0.44790780544281006,
      "learning_rate": 9.956113481743589e-05,
      "loss": 1.184,
      "step": 50
    },
    {
      "epoch": 0.1937984496124031,
      "grad_norm": 0.5336064696311951,
      "learning_rate": 9.900095016148849e-05,
      "loss": 1.0475,
      "step": 75
    },
    {
      "epoch": 0.25839793281653745,
      "grad_norm": 0.7406558990478516,
      "learning_rate": 9.821660752974293e-05,
      "loss": 0.8726,
      "step": 100
    },
    {
      "epoch": 0.32299741602067183,
      "grad_norm": 0.7979248762130737,
      "learning_rate": 9.721169494765758e-05,
      "loss": 0.7652,
      "step": 125
    },
    {
      "epoch": 0.3875968992248062,
      "grad_norm": 0.6833791136741638,
      "learning_rate": 9.599080945201462e-05,
      "loss": 0.6603,
      "step": 150
    },
    {
      "epoch": 0.45219638242894056,
      "grad_norm": 0.7039032578468323,
      "learning_rate": 9.455953606148172e-05,
      "loss": 0.6322,
      "step": 175
    },
    {
      "epoch": 0.5167958656330749,
      "grad_norm": 0.6099870204925537,
      "learning_rate": 9.29244222275874e-05,
      "loss": 0.5543,
      "step": 200
    },
    {
      "epoch": 0.5813953488372093,
      "grad_norm": 0.6576399803161621,
      "learning_rate": 9.109294788298601e-05,
      "loss": 0.5627,
      "step": 225
    },
    {
      "epoch": 0.6459948320413437,
      "grad_norm": 0.5715122222900391,
      "learning_rate": 8.907349122402801e-05,
      "loss": 0.5288,
      "step": 250
    },
    {
      "epoch": 0.710594315245478,
      "grad_norm": 0.5792302489280701,
      "learning_rate": 8.687529038416575e-05,
      "loss": 0.5373,
      "step": 275
    },
    {
      "epoch": 0.7751937984496124,
      "grad_norm": 0.5743929743766785,
      "learning_rate": 8.450840117352204e-05,
      "loss": 0.5252,
      "step": 300
    },
    {
      "epoch": 0.8397932816537468,
      "grad_norm": 0.6231060028076172,
      "learning_rate": 8.198365107794457e-05,
      "loss": 0.5114,
      "step": 325
    },
    {
      "epoch": 0.9043927648578811,
      "grad_norm": 0.5688928365707397,
      "learning_rate": 7.93125897279804e-05,
      "loss": 0.4828,
      "step": 350
    },
    {
      "epoch": 0.9689922480620154,
      "grad_norm": 0.5685861110687256,
      "learning_rate": 7.650743606435351e-05,
      "loss": 0.4917,
      "step": 375
    },
    {
      "epoch": 1.0335917312661498,
      "grad_norm": 0.5789856314659119,
      "learning_rate": 7.358102244164003e-05,
      "loss": 0.482,
      "step": 400
    },
    {
      "epoch": 1.0981912144702843,
      "grad_norm": 0.5516926646232605,
      "learning_rate": 7.054673592584289e-05,
      "loss": 0.4627,
      "step": 425
    },
    {
      "epoch": 1.1627906976744187,
      "grad_norm": 0.6050971150398254,
      "learning_rate": 6.741845705440329e-05,
      "loss": 0.4682,
      "step": 450
    },
    {
      "epoch": 1.227390180878553,
      "grad_norm": 0.656133770942688,
      "learning_rate": 6.421049633879588e-05,
      "loss": 0.4447,
      "step": 475
    },
    {
      "epoch": 1.2919896640826873,
      "grad_norm": 0.5988833904266357,
      "learning_rate": 6.093752880018005e-05,
      "loss": 0.4597,
      "step": 500
    },
    {
      "epoch": 1.3565891472868217,
      "grad_norm": 0.6292406916618347,
      "learning_rate": 5.761452683757852e-05,
      "loss": 0.4503,
      "step": 525
    },
    {
      "epoch": 1.421188630490956,
      "grad_norm": 0.5776403546333313,
      "learning_rate": 5.4256691735681786e-05,
      "loss": 0.4434,
      "step": 550
    },
    {
      "epoch": 1.4857881136950906,
      "grad_norm": 0.5724539756774902,
      "learning_rate": 5.087938412560056e-05,
      "loss": 0.437,
      "step": 575
    },
    {
      "epoch": 1.550387596899225,
      "grad_norm": 0.5992258787155151,
      "learning_rate": 4.749805371667781e-05,
      "loss": 0.4433,
      "step": 600
    },
    {
      "epoch": 1.6149870801033592,
      "grad_norm": 0.585204541683197,
      "learning_rate": 4.412816862080668e-05,
      "loss": 0.435,
      "step": 625
    },
    {
      "epoch": 1.6795865633074936,
      "grad_norm": 0.6437625288963318,
      "learning_rate": 4.078514459256485e-05,
      "loss": 0.4505,
      "step": 650
    },
    {
      "epoch": 1.744186046511628,
      "grad_norm": 0.6194030046463013,
      "learning_rate": 3.7484274508860774e-05,
      "loss": 0.4403,
      "step": 675
    },
    {
      "epoch": 1.8087855297157622,
      "grad_norm": 0.6261780858039856,
      "learning_rate": 3.424065841069152e-05,
      "loss": 0.4341,
      "step": 700
    },
    {
      "epoch": 1.8733850129198966,
      "grad_norm": 0.66021329164505,
      "learning_rate": 3.106913442704105e-05,
      "loss": 0.4273,
      "step": 725
    },
    {
      "epoch": 1.937984496124031,
      "grad_norm": 0.6952248215675354,
      "learning_rate": 2.7984210896911522e-05,
      "loss": 0.416,
      "step": 750
    },
    {
      "epoch": 2.0025839793281652,
      "grad_norm": 0.5859540104866028,
      "learning_rate": 2.500000000000001e-05,
      "loss": 0.421,
      "step": 775
    },
    {
      "epoch": 2.0671834625322996,
      "grad_norm": 0.6241296529769897,
      "learning_rate": 2.2130153199631214e-05,
      "loss": 0.4163,
      "step": 800
    },
    {
      "epoch": 2.1317829457364343,
      "grad_norm": 0.6036105751991272,
      "learning_rate": 1.9387798793266788e-05,
      "loss": 0.4025,
      "step": 825
    },
    {
      "epoch": 2.1963824289405687,
      "grad_norm": 0.6642200946807861,
      "learning_rate": 1.678548185627004e-05,
      "loss": 0.4133,
      "step": 850
    },
    {
      "epoch": 2.260981912144703,
      "grad_norm": 0.6570932269096375,
      "learning_rate": 1.433510685365771e-05,
      "loss": 0.3954,
      "step": 875
    },
    {
      "epoch": 2.3255813953488373,
      "grad_norm": 0.6377525925636292,
      "learning_rate": 1.2047883182364351e-05,
      "loss": 0.4082,
      "step": 900
    },
    {
      "epoch": 2.3901808785529717,
      "grad_norm": 0.6252251863479614,
      "learning_rate": 9.934273893140334e-06,
      "loss": 0.3984,
      "step": 925
    },
    {
      "epoch": 2.454780361757106,
      "grad_norm": 0.6190589666366577,
      "learning_rate": 8.003947826657898e-06,
      "loss": 0.4022,
      "step": 950
    },
    {
      "epoch": 2.5193798449612403,
      "grad_norm": 0.6130039691925049,
      "learning_rate": 6.265735382782106e-06,
      "loss": 0.4101,
      "step": 975
    },
    {
      "epoch": 2.5839793281653747,
      "grad_norm": 0.6172125935554504,
      "learning_rate": 4.727588125342669e-06,
      "loss": 0.399,
      "step": 1000
    },
    {
      "epoch": 2.648578811369509,
      "grad_norm": 0.6302273273468018,
      "learning_rate": 3.396542407197473e-06,
      "loss": 0.4071,
      "step": 1025
    },
    {
      "epoch": 2.7131782945736433,
      "grad_norm": 0.6410745978355408,
      "learning_rate": 2.278687181987016e-06,
      "loss": 0.4042,
      "step": 1050
    },
    {
      "epoch": 2.7777777777777777,
      "grad_norm": 0.5701493620872498,
      "learning_rate": 1.3791361498271705e-06,
      "loss": 0.3891,
      "step": 1075
    },
    {
      "epoch": 2.842377260981912,
      "grad_norm": 0.6222347021102905,
      "learning_rate": 7.02004364361436e-07,
      "loss": 0.3996,
      "step": 1100
    },
    {
      "epoch": 2.9069767441860463,
      "grad_norm": 0.6379964351654053,
      "learning_rate": 2.503894081851921e-07,
      "loss": 0.4045,
      "step": 1125
    },
    {
      "epoch": 2.971576227390181,
      "grad_norm": 0.6062620282173157,
      "learning_rate": 2.6357222756384636e-08,
      "loss": 0.3894,
      "step": 1150
    }
  ],
  "logging_steps": 25,
  "max_steps": 1161,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.194662879381422e+17,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
